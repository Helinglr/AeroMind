{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSORWS4H_F9D"
      },
      "source": [
        "### Fetch Files from GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsl3YDzQyTeN"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgCEAihq3xuh"
      },
      "source": [
        "### Unrar Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNJubR4W33wr"
      },
      "outputs": [],
      "source": [
        "# %pip install unrar\n",
        "# %unrar x \"datasets.rar\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download the Results (For GDrive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import shutil\n",
        "# from google.colab import files\n",
        "\n",
        "# shutil.make_archive('train_results', 'zip', '/content/runs/detect/teknofest_train/teknofest')\n",
        "# files.download('train_results.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCtlTqJo_gvy"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dbPz7NcjUZi",
        "outputId": "139f9bfc-b4b3-49c3-89e5-fca72c3e9ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.4.14  Python-3.11.9 torch-2.10.0+cpu CPU (11th Gen Intel Core i5-11400F @ 2.60GHz)\n",
            "Setup complete  (12 CPUs, 15.8 GB RAM, 412.3/464.3 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxKzqEj0t3og"
      },
      "source": [
        "### Initialize Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9U7yKCTBEOw"
      },
      "outputs": [],
      "source": [
        "# Train parameters\n",
        "# epochs: 50-100 is ideal for the competition but start with 5 for testing.\n",
        "# imgsz: VisDrone images are large. 640 is standard but 1024 may be needed for small objects (if GPU memory allows).\n",
        "# batch: Adjust based on GPU memory. Lower if you get errors (e.g., 8, 4, 2).\n",
        "# device: 0 (uses NVIDIA GPU), cpu (very slow)\n",
        "# n = nano (the fastest), s = small, m = medium, b = base, l = large, x = extra large\n",
        "\n",
        "QUIT_KEY = 'q'\n",
        "DATA_PATH = 'datasets/VisDrone/data.yaml'\n",
        "EPOCHS = 10\n",
        "IMAGE_SIZE = 640\n",
        "BATCH = 8\n",
        "DEVICE = 0 #\"cpu\" for non-nvidia gpu's\n",
        "PROJECT_NAME = 'teknofest_egitim'\n",
        "NAME = 'teknofest'\n",
        "\n",
        "\"\"\"\n",
        "box_loss: How well the model is drawing the box. As this number goes down, it means the model is finding the object's location better.\n",
        "\n",
        "cls_loss (Sınıf Kaybı): Modelin nesneyi ne kadar doğru tanıdığı (Araba mı, kamyon mu?). Bu sayı düştükçe model artık arabayı kamyonla karıştırmaz.\n",
        "\n",
        "dfl_loss: How well the model is adjusting the box boundaries. As this number goes down, it means the model is better at fine-tuning the box edges to fit the object.\n",
        "\n",
        "Instances: The number of objects detected in the image. As this number goes up, it means the model is finding more objects.\n",
        "\n",
        "Size: The size of the model. Larger models (like 'l' or 'x') can capture more details but require more computational resources, while smaller models (like 'n' or 's') are faster but may miss finer details.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# https://docs.ultralytics.com/models/yolov10/#comparisons\n",
        "\n",
        "# https://www.kaggle.com/datasets/shisuiotsutsuki/visdrone2019-det?resource=download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLND4cwK_rUu"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtEz2HNbj3Sb",
        "outputId": "896f19f8-0836-4e1e-e855-d36fc47e818a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from ultralytics import YOLO\n",
        "# MODEL = \"yolov10b.pt\" # (\"yolov10n.pt\")  havier but more accurate, \"yolov10m.pt\" orta yol, \"yolov10s.pt\" hızlı ama daha az doğru\n",
        "# model = YOLO(MODEL)\n",
        "\n",
        "# results = model.train(\n",
        "#     data=DATA_PATH,\n",
        "#     epochs=EPOCHS,\n",
        "#     imgsz=IMAGE_SIZE,\n",
        "#     batch=BATCH,\n",
        "#     device=DEVICE,\n",
        "#     project=PROJECT_NAME,\n",
        "#     name=NAME\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.4.14  Python-3.11.9 torch-2.10.0+cpu CPU (11th Gen Intel Core i5-11400F @ 2.60GHz)\n",
            "YOLOv10b summary (fused): 142 layers, 19,011,822 parameters, 0 gradients, 91.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 464.6127.7 MB/s, size: 254.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\PC\\Desktop\\aeromind\\yolo\\datasets\\VisDrone\\val\\labels... 548 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 548/548 2.0Kit/s 0.3s<0.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\PC\\Desktop\\aeromind\\yolo\\datasets\\VisDrone\\val\\labels.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 35/35 3.2s/it 1:523.3sss\n",
            "                   all        548      38759      0.509      0.394      0.409      0.246\n",
            "            pedestrian        520       8844      0.498      0.449      0.455      0.209\n",
            "                people        482       5125      0.578      0.297       0.36       0.14\n",
            "               bicycle        364       1287      0.231      0.198      0.138     0.0596\n",
            "                   car        515      14064      0.675      0.795      0.803      0.568\n",
            "                   van        421       1975      0.516      0.445      0.451      0.318\n",
            "                 truck        266        750      0.536       0.38      0.397      0.272\n",
            "              tricycle        337       1045      0.479      0.287      0.305      0.173\n",
            "       awning-tricycle        220        532       0.31      0.203      0.165      0.107\n",
            "                   bus        131        251      0.678      0.478      0.559      0.411\n",
            "                 motor        485       4886      0.586      0.413       0.46      0.205\n",
            "Speed: 0.5ms preprocess, 193.4ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\PC\\Desktop\\aeromind\\yolo\\runs\\detect\\val2\u001b[0m\n",
            "Ortalama Hassasiyet (mAP50): 0.4093\n",
            "Genel Hassasiyet (mAP50-95): 0.2462\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('best.pt') \n",
        "\n",
        "results = model.val(data='datasets/VisDrone/data.yaml')\n",
        "\n",
        "print(f\"Precision Mean (mAP50): {results.box.map50:.4f}\")\n",
        "print(f\"Recall Mean (mAR50): {results.box.mar50:.4f}\")\n",
        "print(f\"General Sensitivity (mAP50-95): {results.box.map:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "MODEL = \"best.pt\"\n",
        "model = YOLO(MODEL)\n",
        "\n",
        "source_img = \"test_image.jpg\" \n",
        "results = model.predict(source=source_img, save=True, show=True, conf=0.25)\n",
        "\n",
        "print(\"Test is completed! You can check the 'runs/detect/predict' folder for results.\")\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Video / Cam Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"best.pt\")\n",
        "video_path = \"drone_video.mp4\" \n",
        "cap = cv2.VideoCapture(video_path) #0 for webcam\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Press '{QUIT_KEY}' to exit.\")\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    # stream=true\n",
        "    # conf=0.5: we only show detections with 50% confidence or higher\n",
        "    # verbose=False: To avoid cluttering the terminal with prediction details\n",
        "    results = model.predict(frame, conf=0.5, verbose=False)\n",
        "\n",
        "    # Display the results on the frame\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Show the frame with detections\n",
        "    cv2.imshow(\"YOLOv10 Object Detection\", annotated_frame)\n",
        "\n",
        "    # Exit on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord(QUIT_KEY):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
